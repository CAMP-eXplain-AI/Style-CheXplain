{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUs0FeyYT4Ax",
        "outputId": "0b8fc7e3-9d5e-4f59-9bee-b2a6e094ce02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2YCeJdxwy2-8"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/StyleCheXplain/CheXpert/CheXpert-v1.0-small.zip\" > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q-pjwjQQFJRa"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import lmdb\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import functional as trans_fn\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XsIqbZ2ozwJZ"
      },
      "outputs": [],
      "source": [
        "class CheXPert(Dataset):\n",
        "\n",
        "    def __init__(self, path_to_data, label_file_path, uncertainty=False, transform=None, orientation=\"all\", filter_label=None):\n",
        "        \"\"\" Dataset class for CheXPert\n",
        "\n",
        "        Args:\n",
        "            path_to_data (string): Path to dataset\n",
        "            uncertainty (bool): Changes label calculation\n",
        "            transform (torchvision.Transforms): transforms performed on the samples\n",
        "            orientation (string): \"all\", \"frontal\", \"lateral\"\n",
        "        \"\"\"\n",
        "\n",
        "        self.uncertainty = uncertainty\n",
        "        self.transform = transform\n",
        "        self.path_to_data = path_to_data\n",
        "        self.orientation = orientation\n",
        "        self.filter_label = filter_label\n",
        "\n",
        "        self.PRED_LABEL = [\n",
        "            \"No Finding\",\n",
        "            \"Enlarged Cardiomediastinum\",\n",
        "            \"Cardiomegaly\",\n",
        "            \"Lung Opacity\",\n",
        "            \"Lung Lesion\",\n",
        "            \"Edema\",\n",
        "            \"Consolidation\",\n",
        "            \"Pneumonia\",\n",
        "            \"Atelectasis\",\n",
        "            \"Pneumothorax\",\n",
        "            \"Pleural Effusion\",\n",
        "            \"Pleural Other\",\n",
        "            \"Fracture\",\n",
        "            \"Support Devices\"]\n",
        "\n",
        "        if filter_label is not None:\n",
        "          self.filter_index = self.PRED_LABEL.index(filter_label)\n",
        "\n",
        "        self.labels = pd.read_csv(label_file_path)\n",
        "        \n",
        "        # Deleting either lateral or frontal images of the Dataset or keep all\n",
        "        if self.orientation == \"lateral\":\n",
        "            self.labels = self.labels[~self.labels.Path.str.contains(\"frontal\")]\n",
        "        elif self.orientation == \"frontal\":\n",
        "            self.labels = self.labels[~self.labels.Path.str.contains(\"lateral\")]\n",
        "        elif self.orientation == \"all\":\n",
        "            pass\n",
        "        else:\n",
        "            raise Exception(\"Wrong orientation input given!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            (int): length of the pandas dataframe\n",
        "        \"\"\"\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        - idx (int) : Index of the image to return\n",
        "        Returns:\n",
        "        - image (PIL.Image): PIL format image\n",
        "        \"\"\"\n",
        "\n",
        "        image_path = os.path.join(self.path_to_data, self.labels.iloc[idx]['Path'])\n",
        "        #image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Get labels from the dataframe for current image\n",
        "        label = self.labels.iloc[idx, :].loc[self.PRED_LABEL]\n",
        "        label = label.to_numpy()\n",
        "\n",
        "        # Uncertainty labels are mapped to 0.0\n",
        "        if not self.uncertainty:\n",
        "            tmp = np.zeros(len(self.PRED_LABEL))\n",
        "            tmp[label == 1] = 1.0\n",
        "            label = tmp\n",
        "\n",
        "        if self.filter_label:\n",
        "          labels = labels[self.filter_index].reshape([1])\n",
        "\n",
        "        return image_path, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k_UcBHouCivo"
      },
      "outputs": [],
      "source": [
        "def resize_and_convert(img, size, resample, quality=100):\n",
        "    img = trans_fn.resize(img, size, resample)\n",
        "    img = trans_fn.center_crop(img, size)\n",
        "    buffer = BytesIO()\n",
        "    img.save(buffer, format=\"jpeg\", quality=quality)\n",
        "    val = buffer.getvalue()\n",
        "\n",
        "    return val\n",
        "\n",
        "\n",
        "def resize_multiple(\n",
        "    img, sizes=(128, 256, 512, 1024), resample=Image.LANCZOS, quality=100\n",
        "):\n",
        "    imgs = []\n",
        "\n",
        "    for size in sizes:\n",
        "        imgs.append(resize_and_convert(img, size, resample, quality))\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def resize_worker(img_file, sizes, resample):\n",
        "    i, file, label = img_file\n",
        "    img = Image.open(file)\n",
        "    img = img.convert(\"RGB\")\n",
        "    out = resize_multiple(img, sizes=sizes, resample=resample)\n",
        "\n",
        "    return i, out, label\n",
        "\n",
        "\n",
        "def prepare(\n",
        "    env, dataset, n_worker, sizes=(128, 256, 512, 1024), resample=Image.LANCZOS\n",
        "):\n",
        "    resize_fn = partial(resize_worker, sizes=sizes, resample=resample)\n",
        "\n",
        "    files = [(i, file, label) for i, (file, label) in enumerate(dataset)]\n",
        "    total = 0\n",
        "\n",
        "    idx = 0\n",
        "    with multiprocessing.Pool(n_worker) as pool:\n",
        "        for i, imgs, label in tqdm(pool.imap_unordered(resize_fn, files)):\n",
        "            # skip uncertain\n",
        "            if label[0] == 1 and label[1] == 1:\n",
        "              continue\n",
        "\n",
        "            i = idx\n",
        "            for size, img in zip(sizes, imgs):\n",
        "                key = f\"{size}-{str(i).zfill(5)}\".encode(\"utf-8\")\n",
        "                label_key = f\"{size}-{str(i).zfill(5)}-label\".encode(\"utf-8\")\n",
        "\n",
        "                with env.begin(write=True) as txn:\n",
        "                  txn.put(key, img)\n",
        "                  txn.put(label_key, label.astype(np.uint8))\n",
        "            idx +=1\n",
        "            total += 1\n",
        "\n",
        "        with env.begin(write=True) as txn:\n",
        "            txn.put(\"length\".encode(\"utf-8\"), str(total).encode(\"utf-8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pPequ98HFUA",
        "outputId": "424d9f33-6ba5-4251-bfbd-7fa6eb88a654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make dataset of image sizes: 256\n",
            "Images to process: 202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:424: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "202it [00:01, 102.67it/s]\n"
          ]
        }
      ],
      "source": [
        "resample_map = {\"lanczos\": Image.LANCZOS, \"bilinear\": Image.BILINEAR}\n",
        "resample = resample_map[\"lanczos\"]\n",
        "\n",
        "sizes = [256]\n",
        "\n",
        "print(f\"Make dataset of image sizes:\", \", \".join(str(s) for s in sizes))\n",
        "\n",
        "dataset_path = \"/content/\"\n",
        "label_file_path = \"/content/drive/MyDrive/StyleCheXplain/CheXpert/test.csv\"\n",
        "imgset = CheXPert(dataset_path, label_file_path, orientation=\"frontal\")\n",
        "\n",
        "print(\"Images to process: %d\" % len(imgset))\n",
        "\n",
        "with lmdb.open(\"/content/drive/MyDrive/StyleCheXplain/CheXpert/datasets/mdb/test/\", map_size=1024 ** 4, readahead=False) as env:\n",
        "    prepare(env, imgset, n_worker= 1, sizes=sizes, resample=resample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LASNyBi_n4Qj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chexpert_to_MDB",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}