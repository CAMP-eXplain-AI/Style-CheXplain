{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CheXpert_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "436ef7c0163f447a86e2cee8ae5c5570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d44505d2f0d4435e9316ff38026d71cf",
              "IPY_MODEL_5cb0122f39874e2496ba6f032ec6c03e",
              "IPY_MODEL_971a217ef382410697bbdb984dddcfdb"
            ],
            "layout": "IPY_MODEL_64db40c4db6b43a79c8204b7163c6e83"
          }
        },
        "d44505d2f0d4435e9316ff38026d71cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361e5fdf109e4d3b835e84adedf91b85",
            "placeholder": "​",
            "style": "IPY_MODEL_586f9b472c9b4ebba7cbde922a56de68",
            "value": "100%"
          }
        },
        "5cb0122f39874e2496ba6f032ec6c03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f232b4c5532c4573994daa67af502b4b",
            "max": 32342954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_247fadf77ba34edd8cad0f69ae86d79c",
            "value": 32342954
          }
        },
        "971a217ef382410697bbdb984dddcfdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c803353de64aa8ba748c7762fa0ca7",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b84e0dedbc4ec98390c7be51327f4e",
            "value": " 30.8M/30.8M [00:00&lt;00:00, 113MB/s]"
          }
        },
        "64db40c4db6b43a79c8204b7163c6e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361e5fdf109e4d3b835e84adedf91b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586f9b472c9b4ebba7cbde922a56de68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f232b4c5532c4573994daa67af502b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247fadf77ba34edd8cad0f69ae86d79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3c803353de64aa8ba748c7762fa0ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b84e0dedbc4ec98390c7be51327f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzU3l9r72SMZ",
        "outputId": "74313af8-b6bd-4013-d732-d8a0df82be49"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--jFiECjVlEU"
      },
      "source": [
        "import os\n",
        "from torchvision import transforms as torch_transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torchvision.transforms as torch_transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "import h5py\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "import lmdb\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiResolutionDataset(Dataset):\n",
        "    def __init__(self, path, transform, resolution=256, labels=False, filter_label=None):\n",
        "        self.env = lmdb.open(\n",
        "            path,\n",
        "            max_readers=32,\n",
        "            readonly=True,\n",
        "            lock=False,\n",
        "            readahead=False,\n",
        "            meminit=False,\n",
        "        )\n",
        "\n",
        "        if not self.env:\n",
        "            raise IOError('Cannot open lmdb dataset', path)\n",
        "\n",
        "        self.PRED_LABEL = [\n",
        "            \"No Finding\",\n",
        "            \"Enlarged Cardiomediastinum\",\n",
        "            \"Cardiomegaly\",\n",
        "            \"Lung Opacity\",\n",
        "            \"Lung Lesion\",\n",
        "            \"Edema\",\n",
        "            \"Consolidation\",\n",
        "            \"Pneumonia\",\n",
        "            \"Atelectasis\",\n",
        "            \"Pneumothorax\",\n",
        "            \"Pleural Effusion\",\n",
        "            \"Pleural Other\",\n",
        "            \"Fracture\",\n",
        "            \"Support Devices\"]\n",
        "\n",
        "        if filter_label:\n",
        "          if filter_label not in self.PRED_LABEL:\n",
        "            raise Exception(\"Unrecognized label\")\n",
        "          self.filter_label = self.PRED_LABEL.index(filter_label)\n",
        "        else:\n",
        "          self.filter_label = None\n",
        "\n",
        "        self.resolution = resolution\n",
        "        self.transform = transform\n",
        "        self.labels = labels\n",
        "\n",
        "        with self.env.begin(write=False) as txn:\n",
        "            self.length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
        "    \n",
        "    def pos_weight(self):\n",
        "        labels = np.ndarray(shape=(self.length, 2), dtype=np.uint8)\n",
        "        \n",
        "        with self.env.begin(write=False) as txn:\n",
        "          for idx in range(self.length):\n",
        "            label_key = f\"{self.resolution}-{str(idx).zfill(5)}-label\".encode(\"utf-8\")\n",
        "            label_bytes = txn.get(label_key)\n",
        "            label = np.frombuffer(label_bytes, dtype=np.uint8).copy().astype(np.float32)        \n",
        "            labels[idx, :] = label\n",
        "\n",
        "        num_positives = torch.sum(torch.tensor(labels), dim=0)\n",
        "        num_negatives = self.length - num_positives\n",
        "        pos_weight  = num_negatives / num_positives\n",
        "        \n",
        "        return pos_weight\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with self.env.begin(write=False) as txn:\n",
        "            key = f'{self.resolution}-{str(index).zfill(5)}'.encode('utf-8')\n",
        "            img_bytes = txn.get(key)\n",
        "            if self.labels:\n",
        "                label_key = f\"{self.resolution}-{str(index).zfill(5)}-label\".encode(\"utf-8\")\n",
        "                label_bytes = txn.get(label_key)\n",
        "                label = np.frombuffer(label_bytes, dtype=np.uint8).copy().astype(np.float32)\n",
        "\n",
        "        buffer = BytesIO(img_bytes)\n",
        "        img = Image.open(buffer)\n",
        "\n",
        "        if self.transform is not None:\n",
        "          img = self.transform(img)\n",
        "\n",
        "        if self.filter_label is not None:\n",
        "          label = label[self.filter_label]\n",
        "          label = np.array([0, 1]) if label == 1.0 else np.array([1, 0])\n",
        "\n",
        "        if self.labels:\n",
        "            return img, label.astype(np.float32)\n",
        "        return img"
      ],
      "metadata": {
        "id": "T27sf7VFZmTX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO-JyHoyN5eL"
      },
      "source": [
        "def get_datalaoders(path_to_data, **train_config):\n",
        "    \"\"\" Returns data loaders of given dataset\n",
        "\n",
        "    Arguments:\n",
        "        - dataset (string): 'chexpert', 'brixia', 'combined'\n",
        "        - path_to_data (string): path to the dataset\n",
        "        - train_config (dict): dictionary containing parameters\n",
        "    Returns:\n",
        "        - train_loader (torch.utils.data.DataLoader)\n",
        "        - val_loader (torch.utils.data.DataLoader)\n",
        "        - test_loader (torch.utils.data.DataLoader)\n",
        "    \"\"\"\n",
        "\n",
        "    input_size = train_config['input_size']\n",
        "    batch_size = train_config['batch_size']\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    data_transforms = {\n",
        "        'train': torch_transforms.Compose([\n",
        "            torch_transforms.ToTensor(),\n",
        "            torch_transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': torch_transforms.Compose([\n",
        "            torch_transforms.ToTensor(),\n",
        "            torch_transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "    \n",
        "    image_data = {\n",
        "        'train': MultiResolutionDataset(os.path.join(train_config[\"dataset_path\"], \"train/\"),\n",
        "                           transform=data_transforms['train'], labels=True, filter_label=train_config['experiment_name']),\n",
        "        'val': MultiResolutionDataset(os.path.join(train_config[\"dataset_path\"], \"val/\"),\n",
        "                         transform=data_transforms['val'], labels=True, filter_label=train_config['experiment_name']),\n",
        "        'test': MultiResolutionDataset(os.path.join(train_config[\"dataset_path\"], \"test/\"),\n",
        "                         transform=data_transforms['val'], labels=True, filter_label=train_config['experiment_name']\n",
        "                         )\n",
        "    }\n",
        "    \n",
        "    num_workers = train_config['nof_workers']\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        image_data['train'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=num_workers)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        image_data['val'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=num_workers)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        image_data['test'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=num_workers)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzQCmjsmt7iT"
      },
      "source": [
        "def train_chexpert(model, train_loader, val_loader, **train_config):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        - model (torch.nn.Module): Pytorch model\n",
        "        - train_loader (torch.utils.data.DataLoader): Data loader with training set\n",
        "        - val_loader (torch.utils.data.DataLoader): Data loader with validation set\n",
        "        - train_config (dict): Dictionary of train parameters\n",
        "    Returns:\n",
        "        - (string): Path of the trained model\n",
        "    \"\"\"\n",
        "\n",
        "    device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Process running on: {device}\")\n",
        "\n",
        "    early_stopping = train_config.get('early_stopping', None)\n",
        "    experiment_name = train_config['experiment_name']\n",
        "    n_epochs = train_config['n_epochs']\n",
        "    criterion = train_config['criterion']\n",
        "    optim = train_config['optim'](model.parameters(), **train_config['optim_kwargs'])\n",
        "    scheduler = train_config['scheduler'](optim, **train_config['scheduler_kwargs'])\n",
        "    log_path = train_config['output_path'] + f\"{experiment_name}\"\n",
        "\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "\n",
        "    num_train_batches = len(train_loader)\n",
        "    num_val_batches = len(val_loader)\n",
        "\n",
        "    best_auc = None\n",
        "    early_stopping_val_loss = None\n",
        "\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "    for i_epoch in range(n_epochs):\n",
        "\n",
        "        epoch_train_loss = 0\n",
        "        epoch_val_loss = 0\n",
        "\n",
        "        model = model.train()\n",
        "        for data in tqdm(train_loader):\n",
        "            x, y_target = data\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            x, y_target = x.to(device), y_target.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y_target)\n",
        "\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        epoch_train_loss /= num_train_batches\n",
        "\n",
        "        model = model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "        y_target_list = []\n",
        "        y_raw_pred_list = []\n",
        "        y_pred_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(val_loader):\n",
        "                x, y_target = data\n",
        "\n",
        "                x, y_target = x.to(device), y_target.to(device)\n",
        "                y_pred = model(x)\n",
        "                loss = criterion(y_pred, y_target)\n",
        "                epoch_val_loss += loss.item()\n",
        "\n",
        "                # Apply sigmoid to pred for metrics\n",
        "                y_pred = torch.sigmoid(y_pred)\n",
        "                y_raw_pred_list.extend(y_pred.cpu().tolist())\n",
        "\n",
        "                y_pred[torch.where(y_pred > 0.5)] = 1.0\n",
        "                y_pred[torch.where(y_pred <= 0.5)] = 0\n",
        "\n",
        "                y_pred_list.extend(y_pred.cpu().tolist())\n",
        "                y_target_list.extend(y_target.cpu().tolist())\n",
        "                num_correct += torch.sum(y_pred == y_target).item()\n",
        "                num_examples += y_target.shape[0] * y_target.shape[1]\n",
        "\n",
        "        epoch_val_loss /= num_val_batches\n",
        "        epoch_val_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Compute precision, recall F1-score and support for validations set\n",
        "        epoch_prec, epoch_recall, epoch_f1, epoch_support = precision_recall_fscore_support(y_target_list, y_pred_list,\n",
        "                                                                                            average=\"macro\")\n",
        "\n",
        "        # Calculate average auc\n",
        "        y_target_list = torch.tensor(y_target_list)\n",
        "        y_raw_pred_list = torch.tensor(y_raw_pred_list)\n",
        "        epoch_auc = roc_auc_score(y_target_list, y_raw_pred_list)\n",
        "        \n",
        "        print(\"epoch %d, loss %.2f, acc %.2f, prec %.2f, f1 %.2f, \" % (i_epoch, epoch_val_loss, epoch_val_accuracy, epoch_prec, epoch_f1))\n",
        "\n",
        "        if best_auc is None or best_auc < epoch_auc:\n",
        "            torch.save(model.state_dict(), f\"{log_path}/model.pth\")\n",
        "            best_auc = epoch_auc\n",
        "\n",
        "        if early_stopping is not None and i_epoch % early_stopping == 0:\n",
        "            if early_stopping_val_loss != None and early_stopping_val_loss < epoch_val_loss:\n",
        "                break\n",
        "            else:\n",
        "                # torch.save(model.state_dict(), f\"{log_path}/checkpoint_{i_epoch}.pth\")\n",
        "                early_stopping_val_loss = epoch_val_loss\n",
        "\n",
        "        scheduler.step(epoch_auc)\n",
        "\n",
        "    return f\"{log_path}/model.pth\"\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use 'experiment_name' to specificy the class label"
      ],
      "metadata": {
        "id": "tX_De-pBsGD5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwKkn9QQN7TZ"
      },
      "source": [
        "train_config = {\n",
        "               'batch_size': 64,\n",
        "               'input_size': (256, 256),\n",
        "               'n_epochs': 15,\n",
        "               'nof_workers' : 2,\n",
        "               'optim': torch.optim.Adam,\n",
        "               'weighted_bce': False,\n",
        "               'optim_kwargs': {'lr': 0.001, 'weight_decay': 0.0},\n",
        "               'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "               'scheduler_kwargs': {'factor': 0.1, 'patience': 3, 'mode': 'max'},\n",
        "               'early_stopping': 3,\n",
        "               'experiment_name': \"Cardiomegaly\",\n",
        "               'dataset_path': \"/content/drive/MyDrive/StyleCheXplain/CheXpert/datasets/mdb/\",\n",
        "               'output_path': \"/content/drive/MyDrive/StyleCheXplain/CheXpert/chexpert_classifiers/\"\n",
        "                }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XAwk8JKbAee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439,
          "referenced_widgets": [
            "436ef7c0163f447a86e2cee8ae5c5570",
            "d44505d2f0d4435e9316ff38026d71cf",
            "5cb0122f39874e2496ba6f032ec6c03e",
            "971a217ef382410697bbdb984dddcfdb",
            "64db40c4db6b43a79c8204b7163c6e83",
            "361e5fdf109e4d3b835e84adedf91b85",
            "586f9b472c9b4ebba7cbde922a56de68",
            "f232b4c5532c4573994daa67af502b4b",
            "247fadf77ba34edd8cad0f69ae86d79c",
            "e3c803353de64aa8ba748c7762fa0ca7",
            "e5b84e0dedbc4ec98390c7be51327f4e"
          ]
        },
        "outputId": "6a799a85-e798-424c-a2c2-a8caa53b91c3"
      },
      "source": [
        "# Create data loaders\n",
        "train_loader, val_loader, test_loader = get_datalaoders(path_to_data=\"\", **train_config)\n",
        "\n",
        "# Use weighted BCE\n",
        "if train_config['weighted_bce']:\n",
        "    train_config['criterion'] = torch.nn.BCEWithLogitsLoss(pos_weight=train_loader.dataset.pos_weight())\n",
        "else:\n",
        "    train_config['criterion'] = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Load pretrained model on ImageNet\n",
        "model = models.densenet121(pretrained=True)\n",
        "# Change last layer to CheXpert targets\n",
        "model.classifier = torch.nn.Linear(1024, 2)\n",
        "\n",
        "# Train model\n",
        "pretrained_model_path = train_chexpert(model, train_loader, val_loader, **train_config)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "436ef7c0163f447a86e2cee8ae5c5570"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process running on: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 32/2388 [02:24<2:57:08,  4.51s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-11262e755504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpretrained_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_chexpert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-5ed3ca8f8b2a>\u001b[0m in \u001b[0;36mtrain_chexpert\u001b[0;34m(model, train_loader, val_loader, **train_config)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i5AZopjXL9"
      },
      "source": [
        "def test_chexpert(model, test_loader, **train_config):\n",
        "    \"\"\" Tests a given model and saves results to tensorbaord\n",
        "\n",
        "    Arguments:\n",
        "        - model (torch.nn.Module): Pytorch model\n",
        "        - test_loader (torch.utils.data.DataLoader): Data loader with test set\n",
        "        - train_config (dict): Dictionary of train parameters\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "\n",
        "    device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Process running on: {device}\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "    y_targets = []\n",
        "    y_raw_preds = []\n",
        "    y_preds = []\n",
        "\n",
        "    nb_classes = 2\n",
        "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "    model.to(device)\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader):\n",
        "            x, y_target = data\n",
        "            x, y_target = x.to(device), y_target.to(device)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            _, preds = torch.max(y_pred, 1)\n",
        "            for t, p in zip(y_target.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "            # Apply sigmoid to pred for metrics\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "            y_raw_preds.extend(y_pred.cpu().tolist())\n",
        "\n",
        "            y_pred[torch.where(y_pred > 0.5)] = 1.0\n",
        "            y_pred[torch.where(y_pred <= 0.5)] = 0\n",
        "\n",
        "            y_preds.extend(y_pred.cpu().tolist())\n",
        "            \n",
        "            y_targets.extend(y_target.cpu().tolist())\n",
        "            num_correct += torch.sum(y_pred == y_target).item()\n",
        "            num_examples += y_target.shape[0] * y_target.shape[1]\n",
        "\n",
        "    test_accuracy = num_correct / num_examples\n",
        "\n",
        "    # Compute precision, recall F1-score and support for test set\n",
        "    test_prec, test_recall, test_f1, test_support = precision_recall_fscore_support(y_targets, y_preds,\n",
        "                                                                                    average=\"macro\")\n",
        "\n",
        "    print(confusion_matrix)\n",
        "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
        "    print(test_prec, test_recall, test_f1, test_support, test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU6Ge27skB--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7f9b90-ebfd-4e56-bc7b-1bd34244407e"
      },
      "source": [
        "pretrained_model_path = \"/content/drive/MyDrive/StyleCheXplain/CheXpert/chexpert_classifiers/lung_opacity/model.pth\"\n",
        "# Load trained model\n",
        "model.load_state_dict(torch.load(pretrained_model_path))\n",
        "# Test model\n",
        "test_chexpert(model, val_loader, **train_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process running on: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 584/584 [01:58<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10296.,  8370.],\n",
            "        [10398.,  8268.]])\n",
            "tensor([0.5516, 0.4429])\n",
            "0.650337257084902 0.6488563431183723 0.6471991922545474 None 0.6479427836708453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qNX21YtjcPEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}